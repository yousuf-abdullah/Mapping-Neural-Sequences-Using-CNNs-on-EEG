{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "def DCNN(nb_classes, Chans = 64, Samples = 256, dropoutRate = 0.5):\n",
    "    \n",
    "    input_main   = Input((1, Chans, Samples))\n",
    "    block1       = Conv2D(25, (1, 5), input_shape=(1, Chans, Samples),\n",
    "                    kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)\n",
    "    block1       = Conv2D(25, (Chans, 1), kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block1       = BatchNormalization(axis=1, epsilon=1e-05, momentum=0.1)(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block1)\n",
    "    block1       = Dropout(dropoutRate)(block1)\n",
    "  \n",
    "    block2       = Conv2D(50, (1, 5), kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block2       = BatchNormalization(axis=1, epsilon=1e-05, momentum=0.1)(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block2)\n",
    "    block2       = Dropout(dropoutRate)(block2)\n",
    "    \n",
    "    block3       = Conv2D(100, (1, 5), kernel_constraint = max_norm(2., axis=(0,1,2)))(block2)\n",
    "    block3       = BatchNormalization(axis=1, epsilon=1e-05, momentum=0.1)(block3)\n",
    "    block3       = Activation('elu')(block3)\n",
    "    block3       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block3)\n",
    "    block3       = Dropout(dropoutRate)(block3)\n",
    "    \n",
    "    block4       = Conv2D(200, (1, 5), kernel_constraint = max_norm(2., axis=(0,1,2)))(block3)\n",
    "    block4       = BatchNormalization(axis=1, epsilon=1e-05, momentum=0.1)(block4)\n",
    "    block4       = Activation('elu')(block4)\n",
    "    block4       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block4)\n",
    "    block4       = Dropout(dropoutRate)(block4)\n",
    "    \n",
    "    flatten      = Flatten()(block4)\n",
    "    \n",
    "    dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n",
    "    softmax      = Activation('softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input_main, outputs=softmax)\n",
    "\n",
    "# need these for ShallowConvNet\n",
    "def square(x):\n",
    "    return K.square(x)\n",
    "\n",
    "def log(x):\n",
    "    return K.log(K.clip(x, min_value = 1e-7, max_value = 10000))   \n",
    "\n",
    "\n",
    "def SCNN(nb_classes, Chans = 64, Samples = 128, dropoutRate = 0.5):\n",
    "\n",
    "    input_main   = Input((1, Chans, Samples))\n",
    "    block1       = Conv2D(40, (1, 13), input_shape=(1, Chans, Samples),\n",
    "                        kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)\n",
    "    block1       = Conv2D(40, (Chans, 1), use_bias=False, \n",
    "                        kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block1       = BatchNormalization(axis=1, epsilon=1e-05, momentum=0.1)(block1)\n",
    "    block1       = Activation(square)(block1)\n",
    "    block1       = AveragePooling2D(pool_size=(1, 35), strides=(1, 7))(block1)\n",
    "    block1       = Activation(log)(block1)\n",
    "    block1       = Dropout(dropoutRate)(block1)\n",
    "    flatten      = Flatten()(block1)\n",
    "    dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n",
    "    softmax      = Activation('softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input_main, outputs=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (144, 1, 60, 151)\n",
      "144 train samples\n",
      "72 test samples\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "from mne import io\n",
    "from mne.datasets import sample\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data_path = sample.data_path()\n",
    "\n",
    "raw_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw.fif'\n",
    "event_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw-eve.fif'\n",
    "tmin, tmax = -0., 1\n",
    "event_id = dict(aud_l=1, aud_r=2, vis_l=3, vis_r=4)\n",
    "\n",
    "raw = io.Raw(raw_fname, preload=True, verbose=False)\n",
    "raw.filter(2, None, method='iir')  # replace baseline with high-pass filter\n",
    "events = mne.read_events(event_fname)\n",
    "\n",
    "raw.info['bads'] = ['MEG 2443']  # set bad channels\n",
    "picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False, exclude='bads')\n",
    "\n",
    "epochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=False, picks=picks,\n",
    "                    baseline=None, preload=True, verbose=False)\n",
    "labels = epochs.events[:, -1]\n",
    "\n",
    "# scale data\n",
    "X = epochs.get_data()*1000 # format is in (trials, channels, samples)\n",
    "y = labels\n",
    "\n",
    "kernels, chans, samples = 1, 60, 151\n",
    "\n",
    "X_train      = X[0:144,]\n",
    "Y_train      = y[0:144]\n",
    "X_validate   = X[144:216,]\n",
    "Y_validate   = y[144:216]\n",
    "X_test       = X[216:,]\n",
    "Y_test       = y[216:]\n",
    "\n",
    "Y_train      = np_utils.to_categorical(Y_train-1)\n",
    "Y_validate   = np_utils.to_categorical(Y_validate-1)\n",
    "Y_test       = np_utils.to_categorical(Y_test-1)\n",
    "\n",
    "X_train      = X_train.reshape(X_train.shape[0], kernels, chans, samples)\n",
    "X_validate   = X_validate.reshape(X_validate.shape[0], kernels, chans, samples)\n",
    "X_test       = X_test.reshape(X_test.shape[0], kernels, chans, samples)\n",
    "   \n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yousu\\Anaconda3\\envs\\mne\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\yousu\\Anaconda3\\envs\\mne\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 144 samples, validate on 72 samples\n",
      "WARNING:tensorflow:From C:\\Users\\yousu\\Anaconda3\\envs\\mne\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.33775, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 2s - loss: 1.7863 - acc: 0.2292 - val_loss: 1.3378 - val_acc: 0.3194\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.33775 to 1.30943, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 1.3772 - acc: 0.3611 - val_loss: 1.3094 - val_acc: 0.3750\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.30943\n",
      " - 1s - loss: 1.2565 - acc: 0.4097 - val_loss: 1.3143 - val_acc: 0.3750\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.30943 to 1.28649, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 1.2487 - acc: 0.4306 - val_loss: 1.2865 - val_acc: 0.3750\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.28649 to 1.25704, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 1.1628 - acc: 0.4792 - val_loss: 1.2570 - val_acc: 0.3889\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.25704 to 1.25138, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 1.1903 - acc: 0.4722 - val_loss: 1.2514 - val_acc: 0.3889\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.25138 to 1.21626, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 1.0752 - acc: 0.5694 - val_loss: 1.2163 - val_acc: 0.4167\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.21626 to 1.17616, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 1.0002 - acc: 0.5625 - val_loss: 1.1762 - val_acc: 0.4028\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.17616 to 1.15859, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.8947 - acc: 0.6736 - val_loss: 1.1586 - val_acc: 0.4444\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.15859 to 1.12109, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.7987 - acc: 0.7500 - val_loss: 1.1211 - val_acc: 0.4583\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.12109 to 1.06538, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.7732 - acc: 0.7361 - val_loss: 1.0654 - val_acc: 0.6111\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.06538 to 1.01773, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.6431 - acc: 0.8264 - val_loss: 1.0177 - val_acc: 0.5972\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.01773 to 0.99510, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.6163 - acc: 0.8472 - val_loss: 0.9951 - val_acc: 0.5972\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.99510 to 0.96922, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.5787 - acc: 0.8958 - val_loss: 0.9692 - val_acc: 0.5972\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.96922 to 0.94305, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.5169 - acc: 0.8750 - val_loss: 0.9431 - val_acc: 0.5972\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.94305 to 0.84804, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.4509 - acc: 0.9097 - val_loss: 0.8480 - val_acc: 0.6528\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.84804 to 0.80979, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.3822 - acc: 0.9167 - val_loss: 0.8098 - val_acc: 0.7222\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.80979 to 0.77756, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.3903 - acc: 0.9306 - val_loss: 0.7776 - val_acc: 0.7361\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.77756\n",
      " - 1s - loss: 0.3165 - acc: 0.9653 - val_loss: 0.7990 - val_acc: 0.6806\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.77756 to 0.75222, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.3126 - acc: 0.9583 - val_loss: 0.7522 - val_acc: 0.7083\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.75222 to 0.71933, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.2808 - acc: 0.9792 - val_loss: 0.7193 - val_acc: 0.7500\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.71933 to 0.69483, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.2382 - acc: 0.9861 - val_loss: 0.6948 - val_acc: 0.7083\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.69483 to 0.64114, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.2068 - acc: 0.9861 - val_loss: 0.6411 - val_acc: 0.7917\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.64114 to 0.62161, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.1877 - acc: 0.9931 - val_loss: 0.6216 - val_acc: 0.7778\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.62161\n",
      " - 1s - loss: 0.1773 - acc: 0.9931 - val_loss: 0.6220 - val_acc: 0.7500\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.62161 to 0.61084, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.1277 - acc: 1.0000 - val_loss: 0.6108 - val_acc: 0.7917\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.61084\n",
      " - 1s - loss: 0.1376 - acc: 0.9861 - val_loss: 0.6354 - val_acc: 0.7361\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.61084\n",
      " - 1s - loss: 0.1401 - acc: 0.9931 - val_loss: 0.6305 - val_acc: 0.7639\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.61084 to 0.61034, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.1392 - acc: 0.9931 - val_loss: 0.6103 - val_acc: 0.7361\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.61034 to 0.58988, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.1239 - acc: 1.0000 - val_loss: 0.5899 - val_acc: 0.7917\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.58988\n",
      " - 1s - loss: 0.1102 - acc: 1.0000 - val_loss: 0.5979 - val_acc: 0.7361\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.58988 to 0.57895, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.0979 - acc: 1.0000 - val_loss: 0.5790 - val_acc: 0.8056\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.57895 to 0.54178, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.0905 - acc: 0.9931 - val_loss: 0.5418 - val_acc: 0.7778\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.54178\n",
      " - 1s - loss: 0.0872 - acc: 1.0000 - val_loss: 0.5579 - val_acc: 0.7639\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.54178\n",
      " - 1s - loss: 0.0994 - acc: 0.9931 - val_loss: 0.5724 - val_acc: 0.7639\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.54178 to 0.53947, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.0857 - acc: 1.0000 - val_loss: 0.5395 - val_acc: 0.8056\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.53947 to 0.53444, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.0829 - acc: 0.9931 - val_loss: 0.5344 - val_acc: 0.7500\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.53444\n",
      " - 1s - loss: 0.0894 - acc: 0.9931 - val_loss: 0.5422 - val_acc: 0.7639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.53444\n",
      " - 1s - loss: 0.0698 - acc: 1.0000 - val_loss: 0.5560 - val_acc: 0.7361\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.53444\n",
      " - 1s - loss: 0.0712 - acc: 1.0000 - val_loss: 0.5563 - val_acc: 0.7361\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.53444 to 0.49997, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.0695 - acc: 1.0000 - val_loss: 0.5000 - val_acc: 0.7778\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.49997\n",
      " - 1s - loss: 0.0645 - acc: 1.0000 - val_loss: 0.5607 - val_acc: 0.7361\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.49997\n",
      " - 1s - loss: 0.0682 - acc: 1.0000 - val_loss: 0.5436 - val_acc: 0.7500\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.49997\n",
      " - 1s - loss: 0.0651 - acc: 1.0000 - val_loss: 0.5205 - val_acc: 0.7500\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.49997\n",
      " - 1s - loss: 0.0598 - acc: 1.0000 - val_loss: 0.5100 - val_acc: 0.7917\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.49997\n",
      " - 1s - loss: 0.0480 - acc: 1.0000 - val_loss: 0.5301 - val_acc: 0.7222\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.49997 to 0.48870, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.0460 - acc: 1.0000 - val_loss: 0.4887 - val_acc: 0.7500\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.48870\n",
      " - 1s - loss: 0.0422 - acc: 1.0000 - val_loss: 0.5176 - val_acc: 0.7639\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.48870\n",
      " - 1s - loss: 0.0370 - acc: 1.0000 - val_loss: 0.5129 - val_acc: 0.7500\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.48870\n",
      " - 1s - loss: 0.0349 - acc: 1.0000 - val_loss: 0.5014 - val_acc: 0.7500\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.48870\n",
      " - 1s - loss: 0.0425 - acc: 1.0000 - val_loss: 0.5074 - val_acc: 0.7500\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.48870\n",
      " - 1s - loss: 0.0369 - acc: 1.0000 - val_loss: 0.5306 - val_acc: 0.7778\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.48870\n",
      " - 1s - loss: 0.0377 - acc: 1.0000 - val_loss: 0.5325 - val_acc: 0.7222\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.48870\n",
      " - 1s - loss: 0.0350 - acc: 1.0000 - val_loss: 0.5320 - val_acc: 0.7222\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.48870\n",
      " - 1s - loss: 0.0370 - acc: 1.0000 - val_loss: 0.5292 - val_acc: 0.7361\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.48870\n",
      " - 1s - loss: 0.0328 - acc: 1.0000 - val_loss: 0.4964 - val_acc: 0.7778\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.48870\n",
      " - 1s - loss: 0.0312 - acc: 1.0000 - val_loss: 0.4941 - val_acc: 0.7639\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.48870\n",
      " - 1s - loss: 0.0486 - acc: 0.9931 - val_loss: 0.5740 - val_acc: 0.7361\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.48870\n",
      " - 1s - loss: 0.0435 - acc: 1.0000 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.48870\n",
      " - 1s - loss: 0.0355 - acc: 1.0000 - val_loss: 0.5014 - val_acc: 0.8056\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.48870\n",
      " - 1s - loss: 0.0294 - acc: 1.0000 - val_loss: 0.5165 - val_acc: 0.7778\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.48870\n",
      " - 1s - loss: 0.0295 - acc: 1.0000 - val_loss: 0.5147 - val_acc: 0.7639\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.48870\n",
      " - 1s - loss: 0.0307 - acc: 1.0000 - val_loss: 0.5018 - val_acc: 0.7361\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.48870\n",
      " - 1s - loss: 0.0279 - acc: 1.0000 - val_loss: 0.5123 - val_acc: 0.7500\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.48870 to 0.46985, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.0298 - acc: 1.0000 - val_loss: 0.4698 - val_acc: 0.7639\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0292 - acc: 1.0000 - val_loss: 0.5275 - val_acc: 0.7917\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0320 - acc: 1.0000 - val_loss: 0.5188 - val_acc: 0.7639\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0294 - acc: 1.0000 - val_loss: 0.4902 - val_acc: 0.7778\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0315 - acc: 1.0000 - val_loss: 0.5231 - val_acc: 0.7778\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0293 - acc: 1.0000 - val_loss: 0.4975 - val_acc: 0.7639\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0257 - acc: 1.0000 - val_loss: 0.5115 - val_acc: 0.7361\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0271 - acc: 1.0000 - val_loss: 0.4860 - val_acc: 0.8056\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0260 - acc: 1.0000 - val_loss: 0.4944 - val_acc: 0.7778\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0291 - acc: 1.0000 - val_loss: 0.5223 - val_acc: 0.7917\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0244 - acc: 1.0000 - val_loss: 0.5169 - val_acc: 0.7778\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0199 - acc: 1.0000 - val_loss: 0.4854 - val_acc: 0.7917\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0193 - acc: 1.0000 - val_loss: 0.5137 - val_acc: 0.7778\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0186 - acc: 1.0000 - val_loss: 0.5391 - val_acc: 0.7639\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0225 - acc: 1.0000 - val_loss: 0.4710 - val_acc: 0.7917\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0223 - acc: 1.0000 - val_loss: 0.5351 - val_acc: 0.7222\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0188 - acc: 1.0000 - val_loss: 0.5132 - val_acc: 0.7639\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0210 - acc: 1.0000 - val_loss: 0.6025 - val_acc: 0.7222\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0365 - acc: 1.0000 - val_loss: 0.5447 - val_acc: 0.7778\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0321 - acc: 1.0000 - val_loss: 0.5041 - val_acc: 0.7639\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0275 - acc: 1.0000 - val_loss: 0.5549 - val_acc: 0.7500\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0239 - acc: 1.0000 - val_loss: 0.4914 - val_acc: 0.8056\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0203 - acc: 1.0000 - val_loss: 0.4899 - val_acc: 0.7639\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0247 - acc: 1.0000 - val_loss: 0.5176 - val_acc: 0.7639\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0172 - acc: 1.0000 - val_loss: 0.4704 - val_acc: 0.7917\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0172 - acc: 1.0000 - val_loss: 0.4877 - val_acc: 0.7639\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0174 - acc: 1.0000 - val_loss: 0.5280 - val_acc: 0.7639\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0176 - acc: 1.0000 - val_loss: 0.5039 - val_acc: 0.7917\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0159 - acc: 1.0000 - val_loss: 0.4848 - val_acc: 0.7917\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0138 - acc: 1.0000 - val_loss: 0.4721 - val_acc: 0.7778\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0131 - acc: 1.0000 - val_loss: 0.4993 - val_acc: 0.7639\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0124 - acc: 1.0000 - val_loss: 0.4834 - val_acc: 0.7639\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0158 - acc: 1.0000 - val_loss: 0.5016 - val_acc: 0.7639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/300\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.46985\n",
      " - 1s - loss: 0.0127 - acc: 1.0000 - val_loss: 0.5075 - val_acc: 0.7639\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.46985 to 0.44804, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.0123 - acc: 1.0000 - val_loss: 0.4480 - val_acc: 0.7917\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.44804\n",
      " - 1s - loss: 0.0133 - acc: 1.0000 - val_loss: 0.4633 - val_acc: 0.7639\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.44804\n",
      " - 1s - loss: 0.0146 - acc: 1.0000 - val_loss: 0.4938 - val_acc: 0.7917\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.44804\n",
      " - 1s - loss: 0.0121 - acc: 1.0000 - val_loss: 0.4801 - val_acc: 0.7917\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.44804\n",
      " - 1s - loss: 0.0140 - acc: 1.0000 - val_loss: 0.5244 - val_acc: 0.7639\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.44804\n",
      " - 1s - loss: 0.0104 - acc: 1.0000 - val_loss: 0.4745 - val_acc: 0.7778\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.44804\n",
      " - 1s - loss: 0.0146 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.7639\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.44804\n",
      " - 1s - loss: 0.0148 - acc: 1.0000 - val_loss: 0.4730 - val_acc: 0.7639\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.44804\n",
      " - 1s - loss: 0.0134 - acc: 1.0000 - val_loss: 0.4892 - val_acc: 0.7917\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.44804\n",
      " - 1s - loss: 0.0105 - acc: 1.0000 - val_loss: 0.4492 - val_acc: 0.7778\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.44804 to 0.43741, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.0131 - acc: 1.0000 - val_loss: 0.4374 - val_acc: 0.8056\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0136 - acc: 1.0000 - val_loss: 0.5364 - val_acc: 0.7639\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0125 - acc: 1.0000 - val_loss: 0.4887 - val_acc: 0.7917\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0097 - acc: 1.0000 - val_loss: 0.4616 - val_acc: 0.7778\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0092 - acc: 1.0000 - val_loss: 0.5379 - val_acc: 0.7778\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0093 - acc: 1.0000 - val_loss: 0.4784 - val_acc: 0.7778\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0102 - acc: 1.0000 - val_loss: 0.5031 - val_acc: 0.7778\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0102 - acc: 1.0000 - val_loss: 0.4786 - val_acc: 0.7917\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0109 - acc: 1.0000 - val_loss: 0.4809 - val_acc: 0.7917\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0108 - acc: 1.0000 - val_loss: 0.5144 - val_acc: 0.7500\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0115 - acc: 1.0000 - val_loss: 0.5305 - val_acc: 0.7639\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0101 - acc: 1.0000 - val_loss: 0.5009 - val_acc: 0.7917\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0108 - acc: 1.0000 - val_loss: 0.5189 - val_acc: 0.7778\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0109 - acc: 1.0000 - val_loss: 0.5286 - val_acc: 0.7778\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0107 - acc: 1.0000 - val_loss: 0.5318 - val_acc: 0.7778\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0109 - acc: 1.0000 - val_loss: 0.5278 - val_acc: 0.7778\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0095 - acc: 1.0000 - val_loss: 0.5339 - val_acc: 0.7639\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0129 - acc: 1.0000 - val_loss: 0.4569 - val_acc: 0.7917\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0113 - acc: 1.0000 - val_loss: 0.5478 - val_acc: 0.7639\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0099 - acc: 1.0000 - val_loss: 0.5102 - val_acc: 0.7778\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0085 - acc: 1.0000 - val_loss: 0.4571 - val_acc: 0.7778\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0081 - acc: 1.0000 - val_loss: 0.4946 - val_acc: 0.7917\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0082 - acc: 1.0000 - val_loss: 0.4623 - val_acc: 0.8056\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0081 - acc: 1.0000 - val_loss: 0.4896 - val_acc: 0.7917\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4742 - val_acc: 0.7639\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0073 - acc: 1.0000 - val_loss: 0.4793 - val_acc: 0.7917\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0089 - acc: 1.0000 - val_loss: 0.4936 - val_acc: 0.8056\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4657 - val_acc: 0.7778\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0082 - acc: 1.0000 - val_loss: 0.4591 - val_acc: 0.8056\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0085 - acc: 1.0000 - val_loss: 0.5100 - val_acc: 0.7917\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0100 - acc: 1.0000 - val_loss: 0.5116 - val_acc: 0.7917\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0086 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8056\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0105 - acc: 1.0000 - val_loss: 0.4755 - val_acc: 0.7917\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0085 - acc: 1.0000 - val_loss: 0.4905 - val_acc: 0.7917\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0100 - acc: 1.0000 - val_loss: 0.4789 - val_acc: 0.7917\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0077 - acc: 1.0000 - val_loss: 0.4460 - val_acc: 0.8056\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.43741\n",
      " - 1s - loss: 0.0082 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.7639\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.43741 to 0.43629, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.0079 - acc: 1.0000 - val_loss: 0.4363 - val_acc: 0.8333\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.43629\n",
      " - 1s - loss: 0.0084 - acc: 1.0000 - val_loss: 0.5080 - val_acc: 0.7917\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.43629\n",
      " - 1s - loss: 0.0089 - acc: 1.0000 - val_loss: 0.4999 - val_acc: 0.7778\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.43629\n",
      " - 1s - loss: 0.0082 - acc: 1.0000 - val_loss: 0.5144 - val_acc: 0.8056\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.43629\n",
      " - 1s - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4642 - val_acc: 0.7778\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.43629\n",
      " - 1s - loss: 0.0071 - acc: 1.0000 - val_loss: 0.4890 - val_acc: 0.7778\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.43629\n",
      " - 1s - loss: 0.0079 - acc: 1.0000 - val_loss: 0.4658 - val_acc: 0.8056\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.43629\n",
      " - 1s - loss: 0.0064 - acc: 1.0000 - val_loss: 0.4864 - val_acc: 0.7917\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.43629\n",
      " - 1s - loss: 0.0089 - acc: 1.0000 - val_loss: 0.4485 - val_acc: 0.8194\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.43629\n",
      " - 1s - loss: 0.0077 - acc: 1.0000 - val_loss: 0.4605 - val_acc: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/300\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.43629\n",
      " - 1s - loss: 0.0081 - acc: 1.0000 - val_loss: 0.5037 - val_acc: 0.7917\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.43629\n",
      " - 1s - loss: 0.0080 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.7917\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.43629\n",
      " - 1s - loss: 0.0061 - acc: 1.0000 - val_loss: 0.5467 - val_acc: 0.7778\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.43629\n",
      " - 1s - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4948 - val_acc: 0.8056\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.43629\n",
      " - 1s - loss: 0.0075 - acc: 1.0000 - val_loss: 0.4739 - val_acc: 0.8056\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.43629\n",
      " - 1s - loss: 0.0067 - acc: 1.0000 - val_loss: 0.4664 - val_acc: 0.8056\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.43629\n",
      " - 1s - loss: 0.0072 - acc: 1.0000 - val_loss: 0.4694 - val_acc: 0.7917\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.43629\n",
      " - 1s - loss: 0.0078 - acc: 1.0000 - val_loss: 0.4891 - val_acc: 0.8056\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.43629\n",
      " - 1s - loss: 0.0064 - acc: 1.0000 - val_loss: 0.4989 - val_acc: 0.8056\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.43629\n",
      " - 1s - loss: 0.0067 - acc: 1.0000 - val_loss: 0.4957 - val_acc: 0.7917\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.43629\n",
      " - 1s - loss: 0.0064 - acc: 1.0000 - val_loss: 0.4581 - val_acc: 0.8056\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.43629\n",
      " - 1s - loss: 0.0065 - acc: 1.0000 - val_loss: 0.4992 - val_acc: 0.7778\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.43629\n",
      " - 1s - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4941 - val_acc: 0.8194\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.43629 to 0.43349, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.0069 - acc: 1.0000 - val_loss: 0.4335 - val_acc: 0.8194\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.43349\n",
      " - 1s - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4898 - val_acc: 0.8056\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.43349\n",
      " - 1s - loss: 0.0094 - acc: 1.0000 - val_loss: 0.4858 - val_acc: 0.8056\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.43349\n",
      " - 1s - loss: 0.0096 - acc: 1.0000 - val_loss: 0.4952 - val_acc: 0.8056\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.43349\n",
      " - 1s - loss: 0.0097 - acc: 1.0000 - val_loss: 0.6012 - val_acc: 0.7500\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.43349\n",
      " - 1s - loss: 0.0149 - acc: 1.0000 - val_loss: 0.5080 - val_acc: 0.7778\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.43349\n",
      " - 1s - loss: 0.0142 - acc: 1.0000 - val_loss: 0.4944 - val_acc: 0.7639\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.43349\n",
      " - 1s - loss: 0.0279 - acc: 0.9931 - val_loss: 0.6148 - val_acc: 0.7639\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.43349\n",
      " - 1s - loss: 0.0675 - acc: 0.9861 - val_loss: 0.6719 - val_acc: 0.7361\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.43349\n",
      " - 1s - loss: 0.1047 - acc: 0.9792 - val_loss: 0.6240 - val_acc: 0.7639\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.43349\n",
      " - 1s - loss: 0.1171 - acc: 0.9861 - val_loss: 0.5515 - val_acc: 0.8194\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.43349\n",
      " - 1s - loss: 0.1196 - acc: 1.0000 - val_loss: 0.5666 - val_acc: 0.7778\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.43349\n",
      " - 1s - loss: 0.0882 - acc: 0.9931 - val_loss: 0.4995 - val_acc: 0.8056\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.43349\n",
      " - 1s - loss: 0.0702 - acc: 0.9931 - val_loss: 0.4697 - val_acc: 0.8194\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.43349\n",
      " - 1s - loss: 0.0516 - acc: 1.0000 - val_loss: 0.4780 - val_acc: 0.8056\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.43349\n",
      " - 1s - loss: 0.0387 - acc: 1.0000 - val_loss: 0.4865 - val_acc: 0.7639\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.43349\n",
      " - 1s - loss: 0.0314 - acc: 1.0000 - val_loss: 0.4675 - val_acc: 0.7778\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.43349\n",
      " - 1s - loss: 0.0265 - acc: 1.0000 - val_loss: 0.4602 - val_acc: 0.7917\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.43349\n",
      " - 1s - loss: 0.0282 - acc: 0.9931 - val_loss: 0.5005 - val_acc: 0.7778\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.43349\n",
      " - 1s - loss: 0.0313 - acc: 1.0000 - val_loss: 0.4557 - val_acc: 0.7917\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.43349\n",
      " - 1s - loss: 0.0183 - acc: 1.0000 - val_loss: 0.4503 - val_acc: 0.8056\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.43349 to 0.40590, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_scn.h5\n",
      " - 1s - loss: 0.0164 - acc: 1.0000 - val_loss: 0.4059 - val_acc: 0.8056\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0144 - acc: 1.0000 - val_loss: 0.4316 - val_acc: 0.8194\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0168 - acc: 1.0000 - val_loss: 0.4908 - val_acc: 0.7917\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0118 - acc: 1.0000 - val_loss: 0.4801 - val_acc: 0.7917\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0125 - acc: 1.0000 - val_loss: 0.4375 - val_acc: 0.8056\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0092 - acc: 1.0000 - val_loss: 0.4722 - val_acc: 0.7778\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0100 - acc: 1.0000 - val_loss: 0.4576 - val_acc: 0.7778\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0101 - acc: 1.0000 - val_loss: 0.4472 - val_acc: 0.7917\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0094 - acc: 1.0000 - val_loss: 0.4665 - val_acc: 0.8056\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0086 - acc: 1.0000 - val_loss: 0.4562 - val_acc: 0.7917\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4700 - val_acc: 0.7917\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0076 - acc: 1.0000 - val_loss: 0.4770 - val_acc: 0.7917\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0089 - acc: 1.0000 - val_loss: 0.4527 - val_acc: 0.7778\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0081 - acc: 1.0000 - val_loss: 0.4403 - val_acc: 0.7917\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0088 - acc: 1.0000 - val_loss: 0.4576 - val_acc: 0.7917\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4235 - val_acc: 0.7917\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0076 - acc: 1.0000 - val_loss: 0.4702 - val_acc: 0.7917\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0091 - acc: 1.0000 - val_loss: 0.4839 - val_acc: 0.8194\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0073 - acc: 1.0000 - val_loss: 0.4618 - val_acc: 0.8333\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0072 - acc: 1.0000 - val_loss: 0.4649 - val_acc: 0.7917\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0103 - acc: 1.0000 - val_loss: 0.4800 - val_acc: 0.7917\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0072 - acc: 1.0000 - val_loss: 0.4951 - val_acc: 0.8056\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0072 - acc: 1.0000 - val_loss: 0.4904 - val_acc: 0.7778\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0071 - acc: 1.0000 - val_loss: 0.4527 - val_acc: 0.7917\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0054 - acc: 1.0000 - val_loss: 0.4792 - val_acc: 0.7917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/300\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4795 - val_acc: 0.7917\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4666 - val_acc: 0.7917\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4863 - val_acc: 0.7917\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0080 - acc: 1.0000 - val_loss: 0.4790 - val_acc: 0.8194\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4972 - val_acc: 0.7778\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0058 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.7917\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4551 - val_acc: 0.7917\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0052 - acc: 1.0000 - val_loss: 0.4541 - val_acc: 0.8056\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0068 - acc: 1.0000 - val_loss: 0.5040 - val_acc: 0.7778\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0058 - acc: 1.0000 - val_loss: 0.5023 - val_acc: 0.8056\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4614 - val_acc: 0.7917\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0080 - acc: 1.0000 - val_loss: 0.4566 - val_acc: 0.8056\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0047 - acc: 1.0000 - val_loss: 0.4876 - val_acc: 0.8056\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0079 - acc: 1.0000 - val_loss: 0.4942 - val_acc: 0.8056\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4745 - val_acc: 0.8056\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4739 - val_acc: 0.8056\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0054 - acc: 1.0000 - val_loss: 0.4505 - val_acc: 0.8194\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4633 - val_acc: 0.8472\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4784 - val_acc: 0.8056\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4673 - val_acc: 0.8194\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0056 - acc: 1.0000 - val_loss: 0.4744 - val_acc: 0.8194\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0057 - acc: 1.0000 - val_loss: 0.4639 - val_acc: 0.7917\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0075 - acc: 1.0000 - val_loss: 0.5072 - val_acc: 0.7778\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4653 - val_acc: 0.8056\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4561 - val_acc: 0.7917\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0051 - acc: 1.0000 - val_loss: 0.4665 - val_acc: 0.8056\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0050 - acc: 1.0000 - val_loss: 0.4695 - val_acc: 0.8194\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.4724 - val_acc: 0.8056\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0048 - acc: 1.0000 - val_loss: 0.4741 - val_acc: 0.8056\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.4788 - val_acc: 0.7917\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0052 - acc: 1.0000 - val_loss: 0.4595 - val_acc: 0.8194\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0052 - acc: 1.0000 - val_loss: 0.4833 - val_acc: 0.8056\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0047 - acc: 1.0000 - val_loss: 0.4761 - val_acc: 0.7917\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0048 - acc: 1.0000 - val_loss: 0.4561 - val_acc: 0.8194\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0048 - acc: 1.0000 - val_loss: 0.4602 - val_acc: 0.8056\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0056 - acc: 1.0000 - val_loss: 0.4679 - val_acc: 0.8056\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0037 - acc: 1.0000 - val_loss: 0.4536 - val_acc: 0.8194\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.4949 - val_acc: 0.8056\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0044 - acc: 1.0000 - val_loss: 0.4678 - val_acc: 0.8194\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0049 - acc: 1.0000 - val_loss: 0.4686 - val_acc: 0.7917\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0034 - acc: 1.0000 - val_loss: 0.4983 - val_acc: 0.8056\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0045 - acc: 1.0000 - val_loss: 0.4766 - val_acc: 0.8194\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0055 - acc: 1.0000 - val_loss: 0.4629 - val_acc: 0.8472\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0053 - acc: 1.0000 - val_loss: 0.4504 - val_acc: 0.7917\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0048 - acc: 1.0000 - val_loss: 0.4686 - val_acc: 0.8194\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0045 - acc: 1.0000 - val_loss: 0.4890 - val_acc: 0.7917\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.4736 - val_acc: 0.8056\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0034 - acc: 1.0000 - val_loss: 0.4609 - val_acc: 0.8056\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0034 - acc: 1.0000 - val_loss: 0.4933 - val_acc: 0.8194\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0039 - acc: 1.0000 - val_loss: 0.4736 - val_acc: 0.8056\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0046 - acc: 1.0000 - val_loss: 0.4547 - val_acc: 0.8194\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0041 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.7917\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0035 - acc: 1.0000 - val_loss: 0.4627 - val_acc: 0.8333\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.4555 - val_acc: 0.8194\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0049 - acc: 1.0000 - val_loss: 0.4995 - val_acc: 0.7917\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0045 - acc: 1.0000 - val_loss: 0.4954 - val_acc: 0.8194\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.4819 - val_acc: 0.8056\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.4333 - val_acc: 0.8333\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0050 - acc: 1.0000 - val_loss: 0.4991 - val_acc: 0.8194\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0041 - acc: 1.0000 - val_loss: 0.4714 - val_acc: 0.8056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275/300\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0040 - acc: 1.0000 - val_loss: 0.4495 - val_acc: 0.8056\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4798 - val_acc: 0.8333\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.4676 - val_acc: 0.8194\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0051 - acc: 1.0000 - val_loss: 0.4979 - val_acc: 0.8056\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0051 - acc: 1.0000 - val_loss: 0.4945 - val_acc: 0.8056\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.4863 - val_acc: 0.8056\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0033 - acc: 1.0000 - val_loss: 0.4765 - val_acc: 0.8194\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0040 - acc: 1.0000 - val_loss: 0.4936 - val_acc: 0.8056\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.4698 - val_acc: 0.8194\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0051 - acc: 1.0000 - val_loss: 0.4420 - val_acc: 0.8333\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.4858 - val_acc: 0.8333\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0044 - acc: 1.0000 - val_loss: 0.4610 - val_acc: 0.8194\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.4770 - val_acc: 0.8056\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0037 - acc: 1.0000 - val_loss: 0.5237 - val_acc: 0.7917\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0041 - acc: 1.0000 - val_loss: 0.4819 - val_acc: 0.8333\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0041 - acc: 1.0000 - val_loss: 0.4731 - val_acc: 0.8194\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.4860 - val_acc: 0.8056\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0037 - acc: 1.0000 - val_loss: 0.4900 - val_acc: 0.8056\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0044 - acc: 1.0000 - val_loss: 0.4684 - val_acc: 0.8056\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0055 - acc: 1.0000 - val_loss: 0.5153 - val_acc: 0.8056\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0044 - acc: 1.0000 - val_loss: 0.4684 - val_acc: 0.8194\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.4929 - val_acc: 0.7917\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0033 - acc: 1.0000 - val_loss: 0.4726 - val_acc: 0.8194\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.4897 - val_acc: 0.8333\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0038 - acc: 1.0000 - val_loss: 0.4533 - val_acc: 0.8333\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.40590\n",
      " - 1s - loss: 0.0037 - acc: 1.0000 - val_loss: 0.4545 - val_acc: 0.8194\n",
      "Classification accuracy: 0.958333 \n"
     ]
    }
   ],
   "source": [
    "model = SCNN(nb_classes = 4, Chans = chans, Samples = samples, dropoutRate = 0.5)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "numParams = model.count_params()    \n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='C:\\\\Users\\\\yousu\\\\Documents\\\\EEG Net\\\\checkpoint_scn.h5', \n",
    "                               verbose=2, save_best_only=True)\n",
    "\n",
    "class_weights = {0:1, 1:1, 2:1, 3:1}\n",
    "\n",
    "fittedModel = model.fit(X_train, Y_train, batch_size = 16, epochs = 300, \n",
    "                        verbose = 2, validation_data=(X_validate, Y_validate),\n",
    "                        callbacks=[checkpointer], class_weight = class_weights)\n",
    "\n",
    "# load optimal weights\n",
    "# model.load_weights('/tmp/checkpoint_scn.h5')\n",
    "\n",
    "# WEIGHTS_PATH = /path/to/preset-weights.h5 \n",
    "# model.load_weights(WEIGHTS_PATH)\n",
    "\n",
    "probs       = model.predict(X_test)\n",
    "preds       = probs.argmax(axis = -1)  \n",
    "acc         = np.mean(preds == Y_test.argmax(axis=-1))\n",
    "print(\"Classification accuracy: %f \" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144 samples, validate on 72 samples\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.34274, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 5s - loss: 1.6145 - acc: 0.2431 - val_loss: 1.3427 - val_acc: 0.3750\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.34274 to 1.33441, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 1.5666 - acc: 0.2500 - val_loss: 1.3344 - val_acc: 0.2500\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.33441 to 1.29979, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 1.3941 - acc: 0.3194 - val_loss: 1.2998 - val_acc: 0.3750\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.29979 to 1.25078, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 1.3446 - acc: 0.3681 - val_loss: 1.2508 - val_acc: 0.3611\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.25078 to 1.20617, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 1.4081 - acc: 0.3333 - val_loss: 1.2062 - val_acc: 0.4167\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.20617 to 1.16148, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 1.2345 - acc: 0.4028 - val_loss: 1.1615 - val_acc: 0.4861\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.16148 to 1.12707, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 1.1358 - acc: 0.5139 - val_loss: 1.1271 - val_acc: 0.4861\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.12707 to 1.11885, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 1.1722 - acc: 0.4306 - val_loss: 1.1188 - val_acc: 0.3889\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.11885 to 1.09793, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.9565 - acc: 0.5417 - val_loss: 1.0979 - val_acc: 0.4306\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.09793\n",
      " - 2s - loss: 0.9395 - acc: 0.5833 - val_loss: 1.1046 - val_acc: 0.4444\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.09793 to 1.08653, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.9449 - acc: 0.5903 - val_loss: 1.0865 - val_acc: 0.4167\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.08653 to 1.07170, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.9265 - acc: 0.5833 - val_loss: 1.0717 - val_acc: 0.4028\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.07170\n",
      " - 2s - loss: 0.9074 - acc: 0.5833 - val_loss: 1.0923 - val_acc: 0.4861\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.07170\n",
      " - 1s - loss: 0.7637 - acc: 0.6389 - val_loss: 1.0836 - val_acc: 0.4583\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.07170\n",
      " - 2s - loss: 0.7780 - acc: 0.6319 - val_loss: 1.1034 - val_acc: 0.4861\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.07170 to 1.04809, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.7702 - acc: 0.6389 - val_loss: 1.0481 - val_acc: 0.5139\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.04809\n",
      " - 1s - loss: 0.6384 - acc: 0.7083 - val_loss: 1.0481 - val_acc: 0.5278\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.04809 to 1.00665, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.6890 - acc: 0.6806 - val_loss: 1.0066 - val_acc: 0.5556\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.00665\n",
      " - 1s - loss: 0.5902 - acc: 0.7708 - val_loss: 1.0093 - val_acc: 0.5694\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.00665 to 1.00488, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.6605 - acc: 0.7222 - val_loss: 1.0049 - val_acc: 0.5417\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.00488 to 1.00069, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.6100 - acc: 0.7569 - val_loss: 1.0007 - val_acc: 0.5694\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.00069 to 0.97594, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.6000 - acc: 0.7292 - val_loss: 0.9759 - val_acc: 0.5972\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.97594 to 0.92414, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.5682 - acc: 0.7708 - val_loss: 0.9241 - val_acc: 0.5833\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.92414\n",
      " - 2s - loss: 0.5238 - acc: 0.7917 - val_loss: 0.9644 - val_acc: 0.5972\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.92414\n",
      " - 2s - loss: 0.5770 - acc: 0.7778 - val_loss: 0.9519 - val_acc: 0.5972\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.92414 to 0.89199, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.5475 - acc: 0.7986 - val_loss: 0.8920 - val_acc: 0.6111\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.89199 to 0.88372, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.4490 - acc: 0.8264 - val_loss: 0.8837 - val_acc: 0.6111\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.88372 to 0.85861, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.4704 - acc: 0.7986 - val_loss: 0.8586 - val_acc: 0.6389\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.85861 to 0.83203, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.3724 - acc: 0.8542 - val_loss: 0.8320 - val_acc: 0.6944\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.83203 to 0.79881, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.4717 - acc: 0.7431 - val_loss: 0.7988 - val_acc: 0.6528\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.79881\n",
      " - 1s - loss: 0.3388 - acc: 0.8889 - val_loss: 0.8021 - val_acc: 0.6528\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.79881 to 0.77634, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.3573 - acc: 0.8611 - val_loss: 0.7763 - val_acc: 0.6528\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.77634\n",
      " - 2s - loss: 0.3468 - acc: 0.8889 - val_loss: 0.7926 - val_acc: 0.6806\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.77634\n",
      " - 2s - loss: 0.3683 - acc: 0.8819 - val_loss: 0.8182 - val_acc: 0.6389\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.77634 to 0.70950, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.3230 - acc: 0.8681 - val_loss: 0.7095 - val_acc: 0.7083\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.70950\n",
      " - 1s - loss: 0.3700 - acc: 0.8542 - val_loss: 0.7892 - val_acc: 0.7083\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.70950\n",
      " - 2s - loss: 0.3477 - acc: 0.8750 - val_loss: 0.7386 - val_acc: 0.7222\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.70950\n",
      " - 1s - loss: 0.2771 - acc: 0.8889 - val_loss: 0.7511 - val_acc: 0.6944\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.70950\n",
      " - 1s - loss: 0.2082 - acc: 0.9653 - val_loss: 0.7244 - val_acc: 0.7083\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.70950\n",
      " - 2s - loss: 0.2291 - acc: 0.9375 - val_loss: 0.7431 - val_acc: 0.6667\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.70950\n",
      " - 2s - loss: 0.2581 - acc: 0.8958 - val_loss: 0.7614 - val_acc: 0.6667\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.70950\n",
      " - 1s - loss: 0.2414 - acc: 0.9236 - val_loss: 0.7230 - val_acc: 0.7083\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.70950 to 0.70265, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.2050 - acc: 0.9444 - val_loss: 0.7027 - val_acc: 0.6944\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.70265\n",
      " - 1s - loss: 0.2265 - acc: 0.9236 - val_loss: 0.7190 - val_acc: 0.6806\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.70265\n",
      " - 1s - loss: 0.2395 - acc: 0.9028 - val_loss: 0.7173 - val_acc: 0.6806\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.70265\n",
      " - 1s - loss: 0.2478 - acc: 0.8958 - val_loss: 0.7123 - val_acc: 0.7083\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.70265\n",
      " - 1s - loss: 0.2107 - acc: 0.9236 - val_loss: 0.7044 - val_acc: 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.70265 to 0.70262, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.1902 - acc: 0.9375 - val_loss: 0.7026 - val_acc: 0.7222\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.70262\n",
      " - 1s - loss: 0.1965 - acc: 0.9583 - val_loss: 0.7303 - val_acc: 0.6944\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.70262 to 0.70213, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.2029 - acc: 0.9514 - val_loss: 0.7021 - val_acc: 0.7083\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.70213\n",
      " - 1s - loss: 0.1879 - acc: 0.9514 - val_loss: 0.7416 - val_acc: 0.6944\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.70213 to 0.69975, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.2063 - acc: 0.9444 - val_loss: 0.6997 - val_acc: 0.6944\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.69975\n",
      " - 2s - loss: 0.1885 - acc: 0.9514 - val_loss: 0.8941 - val_acc: 0.6667\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.69975 to 0.67264, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.2119 - acc: 0.9306 - val_loss: 0.6726 - val_acc: 0.7222\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.67264\n",
      " - 1s - loss: 0.2288 - acc: 0.9167 - val_loss: 0.6832 - val_acc: 0.7083\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.67264 to 0.65619, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.1796 - acc: 0.9653 - val_loss: 0.6562 - val_acc: 0.7361\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.65619\n",
      " - 2s - loss: 0.1518 - acc: 0.9583 - val_loss: 0.7501 - val_acc: 0.6806\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.65619 to 0.62774, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.1835 - acc: 0.9583 - val_loss: 0.6277 - val_acc: 0.7222\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.62774\n",
      " - 2s - loss: 0.1549 - acc: 0.9722 - val_loss: 0.6588 - val_acc: 0.6806\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.62774\n",
      " - 2s - loss: 0.1321 - acc: 0.9931 - val_loss: 0.6890 - val_acc: 0.6944\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.62774\n",
      " - 1s - loss: 0.1215 - acc: 0.9653 - val_loss: 0.6777 - val_acc: 0.6806\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.62774 to 0.61741, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.1060 - acc: 0.9792 - val_loss: 0.6174 - val_acc: 0.6944\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.61741\n",
      " - 2s - loss: 0.1155 - acc: 0.9792 - val_loss: 0.6425 - val_acc: 0.6944\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.61741\n",
      " - 2s - loss: 0.1172 - acc: 0.9861 - val_loss: 0.6408 - val_acc: 0.7222\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.61741\n",
      " - 2s - loss: 0.1457 - acc: 0.9653 - val_loss: 0.7926 - val_acc: 0.6667\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.61741\n",
      " - 2s - loss: 0.1460 - acc: 0.9653 - val_loss: 0.6504 - val_acc: 0.7222\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.61741\n",
      " - 1s - loss: 0.1314 - acc: 0.9722 - val_loss: 0.8012 - val_acc: 0.6528\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.61741\n",
      " - 1s - loss: 0.1191 - acc: 0.9722 - val_loss: 0.6273 - val_acc: 0.6944\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.61741\n",
      " - 1s - loss: 0.0958 - acc: 0.9931 - val_loss: 0.7234 - val_acc: 0.6944\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.61741\n",
      " - 2s - loss: 0.1231 - acc: 0.9861 - val_loss: 0.7040 - val_acc: 0.7083\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.61741\n",
      " - 1s - loss: 0.1275 - acc: 0.9792 - val_loss: 0.6814 - val_acc: 0.6944\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.61741\n",
      " - 1s - loss: 0.1207 - acc: 0.9653 - val_loss: 0.6864 - val_acc: 0.6528\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.61741\n",
      " - 2s - loss: 0.1075 - acc: 0.9653 - val_loss: 0.6815 - val_acc: 0.6944\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.61741\n",
      " - 2s - loss: 0.1281 - acc: 0.9653 - val_loss: 0.6185 - val_acc: 0.6944\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.61741\n",
      " - 1s - loss: 0.0896 - acc: 0.9931 - val_loss: 0.7101 - val_acc: 0.6944\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.61741\n",
      " - 1s - loss: 0.1396 - acc: 0.9792 - val_loss: 0.6452 - val_acc: 0.6944\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.61741\n",
      " - 1s - loss: 0.0959 - acc: 0.9861 - val_loss: 0.6922 - val_acc: 0.6944\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.61741\n",
      " - 2s - loss: 0.1091 - acc: 0.9722 - val_loss: 0.7425 - val_acc: 0.7222\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.61741\n",
      " - 1s - loss: 0.0800 - acc: 1.0000 - val_loss: 0.6716 - val_acc: 0.6667\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.61741\n",
      " - 1s - loss: 0.1168 - acc: 0.9653 - val_loss: 0.6765 - val_acc: 0.7083\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.61741 to 0.59926, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.1245 - acc: 0.9583 - val_loss: 0.5993 - val_acc: 0.7222\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.59926 to 0.59064, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.0778 - acc: 0.9722 - val_loss: 0.5906 - val_acc: 0.6944\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0834 - acc: 0.9861 - val_loss: 0.6333 - val_acc: 0.7083\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0914 - acc: 0.9792 - val_loss: 0.5931 - val_acc: 0.7222\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0870 - acc: 0.9861 - val_loss: 0.6743 - val_acc: 0.7222\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0819 - acc: 0.9792 - val_loss: 0.6202 - val_acc: 0.6944\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.1339 - acc: 0.9444 - val_loss: 0.6569 - val_acc: 0.7361\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.1191 - acc: 0.9722 - val_loss: 0.6435 - val_acc: 0.7361\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0659 - acc: 1.0000 - val_loss: 0.7497 - val_acc: 0.6944\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0818 - acc: 0.9861 - val_loss: 0.6416 - val_acc: 0.6944\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0917 - acc: 0.9861 - val_loss: 0.6617 - val_acc: 0.7361\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0619 - acc: 0.9861 - val_loss: 0.6323 - val_acc: 0.6806\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0601 - acc: 0.9931 - val_loss: 0.6522 - val_acc: 0.6944\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0614 - acc: 0.9931 - val_loss: 0.6285 - val_acc: 0.7083\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0819 - acc: 0.9792 - val_loss: 0.5936 - val_acc: 0.6944\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0744 - acc: 1.0000 - val_loss: 0.6885 - val_acc: 0.6806\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0715 - acc: 0.9861 - val_loss: 0.6755 - val_acc: 0.7083\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0524 - acc: 1.0000 - val_loss: 0.7433 - val_acc: 0.6667\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0800 - acc: 0.9861 - val_loss: 0.6312 - val_acc: 0.6944\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0609 - acc: 1.0000 - val_loss: 0.6644 - val_acc: 0.6944\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0477 - acc: 1.0000 - val_loss: 0.6912 - val_acc: 0.6944\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0618 - acc: 0.9861 - val_loss: 0.6462 - val_acc: 0.7083\n",
      "Epoch 103/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00103: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0443 - acc: 0.9931 - val_loss: 0.6198 - val_acc: 0.6944\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0474 - acc: 1.0000 - val_loss: 0.6781 - val_acc: 0.7083\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0490 - acc: 0.9931 - val_loss: 0.5949 - val_acc: 0.7361\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0447 - acc: 1.0000 - val_loss: 0.7617 - val_acc: 0.7222\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0511 - acc: 0.9931 - val_loss: 0.6317 - val_acc: 0.7083\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0488 - acc: 1.0000 - val_loss: 0.6507 - val_acc: 0.7361\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0476 - acc: 0.9931 - val_loss: 0.6975 - val_acc: 0.7222\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0319 - acc: 0.9931 - val_loss: 0.7542 - val_acc: 0.6806\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0442 - acc: 0.9931 - val_loss: 0.6370 - val_acc: 0.6944\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0476 - acc: 0.9861 - val_loss: 0.6780 - val_acc: 0.7361\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0399 - acc: 0.9931 - val_loss: 0.7155 - val_acc: 0.7222\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0317 - acc: 0.9931 - val_loss: 0.6421 - val_acc: 0.7083\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0637 - acc: 0.9861 - val_loss: 0.6338 - val_acc: 0.6944\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0395 - acc: 0.9931 - val_loss: 0.6106 - val_acc: 0.7222\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0542 - acc: 0.9861 - val_loss: 0.6457 - val_acc: 0.7222\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0757 - acc: 0.9931 - val_loss: 0.6343 - val_acc: 0.7083\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0939 - acc: 0.9722 - val_loss: 0.6900 - val_acc: 0.6944\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0710 - acc: 0.9722 - val_loss: 0.7937 - val_acc: 0.7083\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0668 - acc: 0.9861 - val_loss: 0.7583 - val_acc: 0.6528\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0739 - acc: 0.9722 - val_loss: 0.9077 - val_acc: 0.6667\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0611 - acc: 0.9931 - val_loss: 0.8255 - val_acc: 0.6111\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0461 - acc: 1.0000 - val_loss: 0.6817 - val_acc: 0.6944\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0625 - acc: 0.9861 - val_loss: 0.7644 - val_acc: 0.6528\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0458 - acc: 0.9861 - val_loss: 0.7866 - val_acc: 0.6667\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0423 - acc: 0.9861 - val_loss: 0.6273 - val_acc: 0.7222\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0350 - acc: 1.0000 - val_loss: 0.6852 - val_acc: 0.7083\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0332 - acc: 1.0000 - val_loss: 0.7197 - val_acc: 0.6806\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0340 - acc: 0.9931 - val_loss: 0.6081 - val_acc: 0.7639\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0583 - acc: 0.9931 - val_loss: 0.7908 - val_acc: 0.6944\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0291 - acc: 1.0000 - val_loss: 0.6119 - val_acc: 0.6806\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0348 - acc: 0.9931 - val_loss: 0.6421 - val_acc: 0.6944\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0391 - acc: 0.9931 - val_loss: 0.6251 - val_acc: 0.7222\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0439 - acc: 1.0000 - val_loss: 0.6301 - val_acc: 0.7222\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0430 - acc: 0.9861 - val_loss: 0.7643 - val_acc: 0.6944\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0330 - acc: 1.0000 - val_loss: 0.7091 - val_acc: 0.6944\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0636 - acc: 0.9792 - val_loss: 0.6945 - val_acc: 0.7361\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0362 - acc: 0.9931 - val_loss: 0.6783 - val_acc: 0.7500\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0625 - acc: 0.9931 - val_loss: 0.9257 - val_acc: 0.6806\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0386 - acc: 1.0000 - val_loss: 0.8661 - val_acc: 0.6667\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.59064\n",
      " - 2s - loss: 0.0472 - acc: 1.0000 - val_loss: 0.6165 - val_acc: 0.7639\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.59064\n",
      " - 1s - loss: 0.0333 - acc: 0.9931 - val_loss: 0.6929 - val_acc: 0.6806\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.59064 to 0.57967, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.0247 - acc: 1.0000 - val_loss: 0.5797 - val_acc: 0.7222\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0361 - acc: 1.0000 - val_loss: 0.6110 - val_acc: 0.6944\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0242 - acc: 1.0000 - val_loss: 0.6393 - val_acc: 0.7361\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0216 - acc: 1.0000 - val_loss: 0.6787 - val_acc: 0.7083\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0287 - acc: 0.9931 - val_loss: 0.7013 - val_acc: 0.6944\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0248 - acc: 1.0000 - val_loss: 0.7518 - val_acc: 0.7083\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0171 - acc: 1.0000 - val_loss: 0.6556 - val_acc: 0.6944\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0195 - acc: 1.0000 - val_loss: 0.6420 - val_acc: 0.6806\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0130 - acc: 1.0000 - val_loss: 0.6618 - val_acc: 0.7222\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0225 - acc: 1.0000 - val_loss: 0.6378 - val_acc: 0.6944\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0251 - acc: 1.0000 - val_loss: 0.6310 - val_acc: 0.7083\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0153 - acc: 1.0000 - val_loss: 0.6646 - val_acc: 0.7222\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0353 - acc: 0.9931 - val_loss: 0.7070 - val_acc: 0.6944\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0213 - acc: 1.0000 - val_loss: 0.6935 - val_acc: 0.6806\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0625 - acc: 0.9792 - val_loss: 1.0848 - val_acc: 0.6250\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0368 - acc: 0.9861 - val_loss: 0.7123 - val_acc: 0.6806\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0435 - acc: 0.9931 - val_loss: 1.0158 - val_acc: 0.6806\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0528 - acc: 0.9861 - val_loss: 1.1593 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/300\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0454 - acc: 0.9861 - val_loss: 0.8916 - val_acc: 0.7083\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0532 - acc: 0.9861 - val_loss: 0.7501 - val_acc: 0.7361\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0590 - acc: 0.9722 - val_loss: 0.6874 - val_acc: 0.7083\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0328 - acc: 0.9931 - val_loss: 0.6701 - val_acc: 0.7778\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0330 - acc: 1.0000 - val_loss: 0.8272 - val_acc: 0.6528\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0146 - acc: 1.0000 - val_loss: 0.6950 - val_acc: 0.6806\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0204 - acc: 1.0000 - val_loss: 0.6231 - val_acc: 0.6944\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0145 - acc: 1.0000 - val_loss: 0.6412 - val_acc: 0.7083\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0117 - acc: 1.0000 - val_loss: 0.5938 - val_acc: 0.7222\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0188 - acc: 1.0000 - val_loss: 0.5949 - val_acc: 0.7222\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0267 - acc: 1.0000 - val_loss: 1.0150 - val_acc: 0.6528\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0552 - acc: 0.9792 - val_loss: 0.8028 - val_acc: 0.7083\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0688 - acc: 0.9792 - val_loss: 1.1314 - val_acc: 0.6528\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0582 - acc: 0.9931 - val_loss: 0.6603 - val_acc: 0.7361\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0409 - acc: 0.9931 - val_loss: 0.6596 - val_acc: 0.7500\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0310 - acc: 1.0000 - val_loss: 0.7568 - val_acc: 0.6944\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0327 - acc: 0.9861 - val_loss: 0.8346 - val_acc: 0.6528\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0278 - acc: 0.9931 - val_loss: 0.7578 - val_acc: 0.6944\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0274 - acc: 1.0000 - val_loss: 0.7730 - val_acc: 0.7639\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0150 - acc: 1.0000 - val_loss: 0.6719 - val_acc: 0.7361\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0175 - acc: 1.0000 - val_loss: 0.6691 - val_acc: 0.6944\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0165 - acc: 1.0000 - val_loss: 0.7812 - val_acc: 0.6806\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0207 - acc: 1.0000 - val_loss: 0.6697 - val_acc: 0.7361\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0383 - acc: 0.9931 - val_loss: 0.6470 - val_acc: 0.7639\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0363 - acc: 0.9931 - val_loss: 0.8403 - val_acc: 0.6667\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0267 - acc: 0.9931 - val_loss: 0.6966 - val_acc: 0.6528\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0297 - acc: 0.9931 - val_loss: 0.7175 - val_acc: 0.7222\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0273 - acc: 1.0000 - val_loss: 0.6705 - val_acc: 0.7361\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0184 - acc: 1.0000 - val_loss: 0.6123 - val_acc: 0.6667\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0135 - acc: 1.0000 - val_loss: 0.6713 - val_acc: 0.6806\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0330 - acc: 0.9931 - val_loss: 0.6208 - val_acc: 0.6944\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0166 - acc: 1.0000 - val_loss: 0.6367 - val_acc: 0.6944\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0142 - acc: 1.0000 - val_loss: 0.6744 - val_acc: 0.6944\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0202 - acc: 1.0000 - val_loss: 0.7580 - val_acc: 0.6667\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0134 - acc: 1.0000 - val_loss: 0.6654 - val_acc: 0.6806\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0116 - acc: 1.0000 - val_loss: 0.6538 - val_acc: 0.7083\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0170 - acc: 1.0000 - val_loss: 0.6795 - val_acc: 0.6944\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0140 - acc: 1.0000 - val_loss: 0.6766 - val_acc: 0.6944\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0133 - acc: 1.0000 - val_loss: 0.6880 - val_acc: 0.7222\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0195 - acc: 1.0000 - val_loss: 0.7318 - val_acc: 0.6806\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0188 - acc: 1.0000 - val_loss: 0.7014 - val_acc: 0.7222\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0181 - acc: 1.0000 - val_loss: 0.6441 - val_acc: 0.6944\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0115 - acc: 1.0000 - val_loss: 0.6019 - val_acc: 0.7222\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0221 - acc: 0.9931 - val_loss: 1.0331 - val_acc: 0.6250\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0292 - acc: 1.0000 - val_loss: 0.7283 - val_acc: 0.7361\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0246 - acc: 0.9931 - val_loss: 0.6352 - val_acc: 0.7500\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.57967\n",
      " - 2s - loss: 0.0265 - acc: 1.0000 - val_loss: 0.7515 - val_acc: 0.7083\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0217 - acc: 1.0000 - val_loss: 0.6834 - val_acc: 0.7361\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0208 - acc: 1.0000 - val_loss: 0.6567 - val_acc: 0.7778\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.57967\n",
      " - 1s - loss: 0.0183 - acc: 1.0000 - val_loss: 0.6420 - val_acc: 0.7778\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.57967 to 0.57921, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.0190 - acc: 0.9931 - val_loss: 0.5792 - val_acc: 0.7222\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0219 - acc: 0.9931 - val_loss: 0.7150 - val_acc: 0.7083\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.57921\n",
      " - 2s - loss: 0.0172 - acc: 1.0000 - val_loss: 0.6191 - val_acc: 0.7361\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.57921\n",
      " - 2s - loss: 0.0111 - acc: 1.0000 - val_loss: 0.7048 - val_acc: 0.6806\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.57921\n",
      " - 2s - loss: 0.0203 - acc: 1.0000 - val_loss: 0.7727 - val_acc: 0.6944\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0179 - acc: 0.9931 - val_loss: 0.6406 - val_acc: 0.7500\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0189 - acc: 1.0000 - val_loss: 0.6893 - val_acc: 0.7083\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.57921\n",
      " - 2s - loss: 0.0135 - acc: 1.0000 - val_loss: 0.7034 - val_acc: 0.6806\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.57921\n",
      " - 2s - loss: 0.0094 - acc: 1.0000 - val_loss: 0.7094 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/300\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0114 - acc: 1.0000 - val_loss: 0.6581 - val_acc: 0.7361\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.57921\n",
      " - 2s - loss: 0.0262 - acc: 0.9931 - val_loss: 0.6665 - val_acc: 0.7500\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0131 - acc: 1.0000 - val_loss: 0.6613 - val_acc: 0.7222\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0293 - acc: 0.9931 - val_loss: 0.7131 - val_acc: 0.7500\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0183 - acc: 1.0000 - val_loss: 0.7431 - val_acc: 0.7083\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0171 - acc: 1.0000 - val_loss: 0.7095 - val_acc: 0.6667\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0081 - acc: 1.0000 - val_loss: 0.6761 - val_acc: 0.7361\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.57921\n",
      " - 2s - loss: 0.0138 - acc: 1.0000 - val_loss: 0.6774 - val_acc: 0.7083\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0126 - acc: 1.0000 - val_loss: 0.6756 - val_acc: 0.7361\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0106 - acc: 1.0000 - val_loss: 0.6621 - val_acc: 0.7222\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.57921\n",
      " - 2s - loss: 0.0147 - acc: 0.9931 - val_loss: 0.7852 - val_acc: 0.7500\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0143 - acc: 1.0000 - val_loss: 0.7211 - val_acc: 0.7222\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.57921\n",
      " - 2s - loss: 0.0146 - acc: 1.0000 - val_loss: 0.7517 - val_acc: 0.6944\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0124 - acc: 1.0000 - val_loss: 0.7030 - val_acc: 0.7083\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0118 - acc: 1.0000 - val_loss: 0.6428 - val_acc: 0.7639\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0120 - acc: 1.0000 - val_loss: 0.6015 - val_acc: 0.7500\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.57921\n",
      " - 2s - loss: 0.0090 - acc: 1.0000 - val_loss: 0.6251 - val_acc: 0.7500\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0090 - acc: 1.0000 - val_loss: 0.6209 - val_acc: 0.6944\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0106 - acc: 1.0000 - val_loss: 0.8187 - val_acc: 0.6944\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.57921\n",
      " - 2s - loss: 0.0100 - acc: 1.0000 - val_loss: 0.6438 - val_acc: 0.7222\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0280 - acc: 0.9931 - val_loss: 0.7259 - val_acc: 0.6806\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0135 - acc: 1.0000 - val_loss: 0.7359 - val_acc: 0.7917\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.57921\n",
      " - 2s - loss: 0.0110 - acc: 1.0000 - val_loss: 0.7183 - val_acc: 0.7222\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0121 - acc: 1.0000 - val_loss: 0.8151 - val_acc: 0.6944\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0100 - acc: 1.0000 - val_loss: 0.8249 - val_acc: 0.6667\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0080 - acc: 1.0000 - val_loss: 0.6463 - val_acc: 0.7361\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0121 - acc: 1.0000 - val_loss: 0.7411 - val_acc: 0.6806\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0081 - acc: 1.0000 - val_loss: 0.6701 - val_acc: 0.8056\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0120 - acc: 1.0000 - val_loss: 0.5903 - val_acc: 0.7639\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0058 - acc: 1.0000 - val_loss: 0.6134 - val_acc: 0.7361\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.57921\n",
      " - 2s - loss: 0.0083 - acc: 1.0000 - val_loss: 0.7148 - val_acc: 0.7083\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0084 - acc: 1.0000 - val_loss: 0.6387 - val_acc: 0.7083\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0055 - acc: 1.0000 - val_loss: 0.6275 - val_acc: 0.7361\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.57921\n",
      " - 2s - loss: 0.0053 - acc: 1.0000 - val_loss: 0.6434 - val_acc: 0.7222\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0045 - acc: 1.0000 - val_loss: 0.6495 - val_acc: 0.7222\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0061 - acc: 1.0000 - val_loss: 0.6325 - val_acc: 0.7222\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0086 - acc: 1.0000 - val_loss: 0.7048 - val_acc: 0.6944\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0110 - acc: 0.9931 - val_loss: 0.7721 - val_acc: 0.7917\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0070 - acc: 1.0000 - val_loss: 0.6811 - val_acc: 0.7222\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0069 - acc: 1.0000 - val_loss: 0.7732 - val_acc: 0.6389\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0114 - acc: 1.0000 - val_loss: 0.7749 - val_acc: 0.6528\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0073 - acc: 1.0000 - val_loss: 0.7469 - val_acc: 0.6667\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.57921\n",
      " - 2s - loss: 0.0083 - acc: 1.0000 - val_loss: 0.8176 - val_acc: 0.6667\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.57921\n",
      " - 2s - loss: 0.0116 - acc: 0.9931 - val_loss: 0.7621 - val_acc: 0.6944\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0045 - acc: 1.0000 - val_loss: 0.7794 - val_acc: 0.6806\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0198 - acc: 0.9931 - val_loss: 0.7408 - val_acc: 0.7639\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0068 - acc: 1.0000 - val_loss: 0.7478 - val_acc: 0.7222\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0095 - acc: 1.0000 - val_loss: 0.7074 - val_acc: 0.7639\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0128 - acc: 1.0000 - val_loss: 0.6730 - val_acc: 0.7361\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0098 - acc: 1.0000 - val_loss: 0.6788 - val_acc: 0.6944\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0163 - acc: 1.0000 - val_loss: 0.9301 - val_acc: 0.7083\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0084 - acc: 1.0000 - val_loss: 0.7160 - val_acc: 0.6944\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0111 - acc: 1.0000 - val_loss: 0.7773 - val_acc: 0.6806\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0064 - acc: 1.0000 - val_loss: 0.7696 - val_acc: 0.7083\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0056 - acc: 1.0000 - val_loss: 0.8660 - val_acc: 0.6389\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0109 - acc: 1.0000 - val_loss: 0.7725 - val_acc: 0.7500\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0174 - acc: 1.0000 - val_loss: 1.1429 - val_acc: 0.7083\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0111 - acc: 1.0000 - val_loss: 0.6016 - val_acc: 0.7639\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0094 - acc: 1.0000 - val_loss: 0.8426 - val_acc: 0.7083\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0336 - acc: 0.9861 - val_loss: 0.6217 - val_acc: 0.8056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/300\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.57921\n",
      " - 2s - loss: 0.0179 - acc: 0.9931 - val_loss: 0.6352 - val_acc: 0.7778\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0228 - acc: 0.9931 - val_loss: 0.8741 - val_acc: 0.7083\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0206 - acc: 0.9931 - val_loss: 0.7229 - val_acc: 0.7639\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0238 - acc: 0.9931 - val_loss: 0.9032 - val_acc: 0.6806\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0178 - acc: 1.0000 - val_loss: 0.7315 - val_acc: 0.7083\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.57921\n",
      " - 2s - loss: 0.0232 - acc: 0.9931 - val_loss: 0.8207 - val_acc: 0.6806\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.57921\n",
      " - 2s - loss: 0.0223 - acc: 1.0000 - val_loss: 0.5904 - val_acc: 0.7500\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0211 - acc: 0.9931 - val_loss: 0.9270 - val_acc: 0.6667\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0252 - acc: 0.9931 - val_loss: 0.7460 - val_acc: 0.7083\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.57921\n",
      " - 2s - loss: 0.0252 - acc: 0.9931 - val_loss: 0.7765 - val_acc: 0.7361\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0181 - acc: 1.0000 - val_loss: 0.6862 - val_acc: 0.7639\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.57921\n",
      " - 2s - loss: 0.0205 - acc: 0.9931 - val_loss: 0.6889 - val_acc: 0.7222\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0079 - acc: 1.0000 - val_loss: 0.6173 - val_acc: 0.7083\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.57921\n",
      " - 2s - loss: 0.0128 - acc: 1.0000 - val_loss: 0.6453 - val_acc: 0.7500\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0179 - acc: 1.0000 - val_loss: 0.5932 - val_acc: 0.7361\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.57921\n",
      " - 1s - loss: 0.0078 - acc: 1.0000 - val_loss: 0.6525 - val_acc: 0.7222\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 00297: val_loss improved from 0.57921 to 0.56461, saving model to C:\\Users\\yousu\\Documents\\EEG Net\\checkpoint_dcn.h5\n",
      " - 2s - loss: 0.0114 - acc: 0.9931 - val_loss: 0.5646 - val_acc: 0.7778\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.56461\n",
      " - 2s - loss: 0.0093 - acc: 1.0000 - val_loss: 0.7120 - val_acc: 0.7083\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.56461\n",
      " - 1s - loss: 0.0120 - acc: 0.9931 - val_loss: 0.9509 - val_acc: 0.7222\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.56461\n",
      " - 2s - loss: 0.0137 - acc: 1.0000 - val_loss: 0.7232 - val_acc: 0.7361\n",
      "Classification accuracy: 0.958333 \n"
     ]
    }
   ],
   "source": [
    "model = DCNN(nb_classes = 4, Chans = chans, Samples = samples, dropoutRate = 0.5)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "numParams    = model.count_params()    \n",
    "checkpointer = ModelCheckpoint(filepath='C:\\\\Users\\\\yousu\\\\Documents\\\\EEG Net\\\\checkpoint_dcn.h5', \n",
    "                               verbose=2, save_best_only=True)\n",
    "\n",
    "class_weights = {0:1, 1:1, 2:1, 3:1}\n",
    "\n",
    "fittedModel = model.fit(X_train, Y_train, batch_size = 16, epochs = 300, \n",
    "                        verbose = 2, validation_data=(X_validate, Y_validate),\n",
    "                        callbacks=[checkpointer], class_weight = class_weights)\n",
    "\n",
    "# load optimal weights\n",
    "#model.load_weights('/tmp/checkpoint_dcn.h5')\n",
    "\n",
    "# WEIGHTS_PATH = /path/to/some-preset-weights.h5 \n",
    "# model.load_weights(WEIGHTS_PATH)\n",
    "\n",
    "prob = model.predict(X_test)\n",
    "pred = prob.argmax(axis = -1)  \n",
    "acc = np.mean(preds == Y_test.argmax(axis=-1))\n",
    "\n",
    "print(\"Classification accuracy: %f \" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x277e17445f8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyriemann.utils.viz import plot_confusion_matrix\n",
    "\n",
    "# confusion matrices for both classifiers\n",
    "names = ['Auditory Stimulus Left', 'Auditory Stimulus Right', \n",
    "         'Visual Stimulus Left', 'Visual Stimulus Right']\n",
    "plt.figure(0)\n",
    "plot_confusion_matrix(preds, Y_test.argmax(axis = -1), names, title = 'Shallow CNN')\n",
    "\n",
    "plt.figure(1)\n",
    "plot_confusion_matrix(pred, Y_test.argmax(axis = -1), names, title = 'Deep CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
